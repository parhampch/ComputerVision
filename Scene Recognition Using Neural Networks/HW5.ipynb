{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a9FFb4YSehd"
      },
      "source": [
        "بخش پایین برای لاگین کردن در اکانتی است که قرار است داده‌های سوال با فرمت گفته شده در درایو آن اکانت باشند. در صورتی که آدرس ذخیره داده با آدرس پیشفرض تفاوت دارد لطفا جهت کارکرد صحیح برنامه آدرس را به روز کنید. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyO_dNDMRam7"
      },
      "source": [
        "from google.colab import drive\n",
        " drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WrLGSoJR_pM"
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmTQWBJhSWTD"
      },
      "source": [
        "بخش پایین مربوط به تعریف ترنسفورم‌های مذکور در گزارش است."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XORlJAXSFRz"
      },
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YYNfJSgSkWv"
      },
      "source": [
        "پخش پایین مربوط به لود کردن داده‌ها است."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmR1JNuhSScy"
      },
      "source": [
        "data_dir = \"/content/gdrive/My Drive/CoputerVision/Data\"\n",
        "dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
        "         for x in ['train', 'val']}\n",
        "dst_loader = {x: torch.utils.data.DataLoader(dsets[x], batch_size=batch_size,\n",
        "                                               shuffle=True, num_workers=2)\n",
        "                for x in ['train', 'val']}\n",
        "dset_sizes = {x: len(dsets[x]) for x in ['train', 'val']}\n",
        "dset_classes = dsets['train'].classes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9nGO8mXS0DQ"
      },
      "source": [
        "کد زیر مربوط به تابع آموزش و اعتبار سنجی است که در گزارش توضیح داده شده است"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6608FwqS5Dj"
      },
      "source": [
        "def train_and_val_network(model, criterion, optimizer, scheduler, num_epochs):\n",
        "  best_model = model;\n",
        "  best_acc = 0.0;\n",
        "  epochs_number = []\n",
        "  train_loss_values = []\n",
        "  val_loss_values = []\n",
        "  train_acc_values = []\n",
        "  val_acc_values = []\n",
        "  train_acc_t5_values = []\n",
        "  val_acc_t5_values = []\n",
        "  for epoch in tqdm(range(num_epochs)):\n",
        "    for phase in ['train', 'val']:\n",
        "      if phase == 'train':\n",
        "        scheduler.step()\n",
        "        model.train() \n",
        "      else:\n",
        "        model.eval()\n",
        "      current_loss = 0.0\n",
        "      current_corrects = 0\n",
        "      current_corrects_t5 = 0\n",
        "      for data in dst_loader[phase]:\n",
        "        inputs, labels = data\n",
        "        if torch.cuda.is_available():\n",
        "          inputs = inputs.to('cuda')\n",
        "          labels = labels.to('cuda')\n",
        "        inputs, labels = Variable(inputs), Variable(labels)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        _, predsP = outputs.topk(5, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        if phase == 'train':\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "        current_loss += loss.item()\n",
        "        current_corrects += torch.sum(preds == labels.data)\n",
        "        current_corrects_t5 += torch.sum(predsP == labels.view(-1, 1).expand_as(predsP))\n",
        "      epoch_loss = current_loss / dset_sizes[phase]\n",
        "      epoch_acc = current_corrects.item() / float(dset_sizes[phase])\n",
        "      epoch_acc_t5 = current_corrects_t5.item() / float(dset_sizes[phase])\n",
        "      epochs_number.append(epoch)\n",
        "      if phase == 'train':\n",
        "        train_loss_values.append(epoch_loss)\n",
        "        train_acc_values.append(epoch_acc)\n",
        "        train_acc_t5_values.append(epoch_acc_t5)\n",
        "      else:\n",
        "        if epoch_acc > best_acc:\n",
        "          best_acc = epoch_acc\n",
        "          best_model = copy.deepcopy(model)\n",
        "        val_loss_values.append(epoch_loss)\n",
        "        val_acc_values.append(epoch_acc)\n",
        "        val_acc_t5_values.append(epoch_acc_t5)\n",
        "  return best_model, train_loss_values, val_loss_values, train_acc_values, val_acc_values, train_acc_t5_values, val_acc_t5_values, best_acc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkEqzwPYTHZb"
      },
      "source": [
        " پارامترها و کد اصلی و رسم نمودار مربوط به بخش 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u5cuVksTHJM"
      },
      "source": [
        "# define parameters\n",
        "num_epochs = 40\n",
        "num_classes = 15\n",
        "feature_extract = False\n",
        "use_pretrained = False\n",
        "input_size = 224\n",
        "base_lr = 0.001\n",
        "batch_size = 10\n",
        "# main code\n",
        "model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "model_ft.features[2] = nn.MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
        "model_ft.features = model_ft.features[:3]\n",
        "model_ft.classifier[4] = nn.Linear(in_features=2304, out_features=4096, bias=True)\n",
        "num_ftrs = model_ft.classifier[6].in_features\n",
        "model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "model_ft.classifier = model_ft.classifier[3:7]\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer_ft, gamma=0.9)\n",
        "if torch.cuda.is_available():\n",
        "  model_ft = model_ft.to('cuda')\n",
        "  criterion = criterion.to('cuda')\n",
        "model_ft, train_loss_values, val_loss_values, train_acc_values, val_acc_values, train_acc_t5_values, val_acc_t5_values, best_acc = train_and_val_network(model_ft, criterion, optimizer_ft, scheduler, num_epochs)\n",
        "torch.save(model_ft, 'best_model_p1.pth')\n",
        "print(best_acc)\n",
        "# draw charts\n",
        "from google.colab import files\n",
        "plt.figure\n",
        "plt.title(\"Accuracy vs. Number of Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.plot(range(1,num_epochs+1),train_acc_values, label=\"Train\")\n",
        "plt.plot(range(1,num_epochs+1),val_acc_values, label=\"Val\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.savefig('Acc_p1.png')\n",
        "files.download('Acc_p1.png')\n",
        "plt.clf()\n",
        "plt.close()\n",
        "plt.figure\n",
        "plt.title(\"Accuracy(top 5) vs. Number of Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.plot(range(1,num_epochs+1),train_acc_t5_values, label=\"Train\")\n",
        "plt.plot(range(1,num_epochs+1),val_acc_t5_values, label=\"Val\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.savefig('AccT5_p1.png')\n",
        "files.download('AccT5_p1.png')\n",
        "plt.clf()\n",
        "plt.close()\n",
        "plt.figure()\n",
        "plt.title(\"Loss vs. Number of Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(range(1,num_epochs+1),train_loss_values, label=\"Train\")\n",
        "plt.plot(range(1,num_epochs+1),val_loss_values, label=\"Val\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.savefig('Loss_p1.png')\n",
        "files.download('Loss_p1.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEV2-jPtTjGw"
      },
      "source": [
        " پارامترها و کد اصلی و رسم نمودار مربوط به بخش 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WW1Pyx7Tn-R"
      },
      "source": [
        "# define parameters\n",
        "num_epochs = 40\n",
        "num_classes = 15\n",
        "feature_extract = False\n",
        "use_pretrained = False\n",
        "input_size = 224\n",
        "base_lr = 0.001\n",
        "batch_size = 32\n",
        "# main code\n",
        "model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "model_ft.features[6] = nn.Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "model_ft.features[8] = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
        "model_ft.features = model_ft.features[:9]\n",
        "num_ftrs = model_ft.classifier[6].in_features\n",
        "model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if torch.cuda.is_available():\n",
        "  model_ft = model_ft.to('cuda')\n",
        "  criterion = criterion.to('cuda')\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer_ft, gamma=0.9)\n",
        "\n",
        "model_ft, train_loss_values, val_loss_values, train_acc_values, val_acc_values, train_acc_t5_values, val_acc_t5_values,  best_acc = train_and_val_network(model_ft, criterion, optimizer_ft, scheduler, num_epochs)\n",
        "torch.save(model_ft, 'best_model_p3.pth')\n",
        "print(best_acc)\n",
        "#draw charts\n",
        "from google.colab import files\n",
        "plt.figure\n",
        "plt.title(\"Accuracy vs. Number of Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.plot(range(1,num_epochs+1),train_acc_values, label=\"Train\")\n",
        "plt.plot(range(1,num_epochs+1),val_acc_values, label=\"Val\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.savefig('Acc_p2.png')\n",
        "files.download('Acc_p2.png')\n",
        "plt.clf()\n",
        "plt.close()\n",
        "plt.figure\n",
        "plt.title(\"Accuracy(top 5) vs. Number of Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.plot(range(1,num_epochs+1),train_acc_t5_values, label=\"Train\")\n",
        "plt.plot(range(1,num_epochs+1),val_acc_t5_values, label=\"Val\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.savefig('AccT5_p2.png')\n",
        "files.download('AccT5_p2.png')\n",
        "plt.clf()\n",
        "plt.close()\n",
        "plt.figure()\n",
        "plt.title(\"Loss vs. Number of Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(range(1,num_epochs+1),train_loss_values, label=\"Train\")\n",
        "plt.plot(range(1,num_epochs+1),val_loss_values, label=\"Val\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.savefig('Loss_p2.png')\n",
        "files.download('Loss_p2.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrvNA3QfT1jn"
      },
      "source": [
        " پارامترها و کد اصلی و رسم نمودار مربوط به بخش 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ2S-C4hT4aT"
      },
      "source": [
        "# define parameters\n",
        "num_epochs = 40\n",
        "num_classes = 15\n",
        "feature_extract = False\n",
        "use_pretrained = False\n",
        "input_size = 224\n",
        "base_lr = 0.001\n",
        "batch_size = 32\n",
        "# main code\n",
        "model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "num_ftrs = model_ft.classifier[6].in_features\n",
        "model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if torch.cuda.is_available():\n",
        "  model_ft = model_ft.to('cuda')\n",
        "  criterion = criterion.to('cuda')\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer_ft, gamma=0.9)\n",
        "\n",
        "model_ft, train_loss_values, val_loss_values, train_acc_values, val_acc_values, train_acc_t5_values, val_acc_t5_values, best_acc = train_and_val_network(model_ft, criterion, optimizer_ft, scheduler, num_epochs)\n",
        "torch.save(model_ft, 'best_model_p3.pth')\n",
        "print(best_acc)\n",
        "# draw charts\n",
        "from google.colab import files\n",
        "plt.figure\n",
        "plt.title(\"Accuracy vs. Number of Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.plot(range(1,num_epochs+1),train_acc_values, label=\"Train\")\n",
        "plt.plot(range(1,num_epochs+1),val_acc_values, label=\"Val\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.savefig('Acc_p3.png')\n",
        "files.download('Acc_p3.png')\n",
        "plt.clf()\n",
        "plt.close()\n",
        "plt.figure\n",
        "plt.title(\"Accuracy(top 5) vs. Number of Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.plot(range(1,num_epochs+1),train_acc_t5_values, label=\"Train\")\n",
        "plt.plot(range(1,num_epochs+1),val_acc_t5_values, label=\"Val\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.savefig('AccT5_p3.png')\n",
        "files.download('AccT5_p3.png')\n",
        "plt.clf()\n",
        "plt.close()\n",
        "plt.figure()\n",
        "plt.title(\"Loss vs. Number of Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(range(1,num_epochs+1),train_loss_values, label=\"Train\")\n",
        "plt.plot(range(1,num_epochs+1),val_loss_values, label=\"Val\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.savefig('Loss_p3.png')\n",
        "files.download('Loss_p3.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VpsvVUOT2iT"
      },
      "source": [
        " پارامترها و کد اصلی و رسم نمودار مربوط به بخش 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmXgfSIuUAXr"
      },
      "source": [
        "# define parameters\n",
        "num_epochs = 30\n",
        "num_classes = 15\n",
        "feature_extract = True\n",
        "use_pretrained = True\n",
        "input_size = 224\n",
        "base_lr = 0.001\n",
        "batch_size = 32\n",
        "# main code\n",
        "model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "if feature_extract:\n",
        "  for param in model_ft.parameters():\n",
        "    param.requires_grad = False\n",
        "num_ftrs = model_ft.classifier[6].in_features\n",
        "model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if torch.cuda.is_available():\n",
        "  model_ft = model_ft.to('cuda')\n",
        "  criterion = criterion.to('cuda')\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer_ft, gamma=0.9)\n",
        "\n",
        "model_ft, train_loss_values, val_loss_values, train_acc_values, val_acc_values, train_acc_t5_values, val_acc_t5_values, best_acc = train_and_val_network(model_ft, criterion, optimizer_ft, scheduler, num_epochs)\n",
        "torch.save(model_ft, 'best_model_p4.pth')\n",
        "print(best_acc)\n",
        "# draw charts\n",
        "from google.colab import files\n",
        "plt.figure\n",
        "plt.title(\"Accuracy vs. Number of Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.plot(range(1,num_epochs+1),train_acc_values, label=\"Train\")\n",
        "plt.plot(range(1,num_epochs+1),val_acc_values, label=\"Val\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.savefig('Acc_p4.png')\n",
        "files.download('Acc_p4.png')\n",
        "plt.clf()\n",
        "plt.close()\n",
        "plt.figure\n",
        "plt.title(\"Accuracy(top 5) vs. Number of Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.plot(range(1,num_epochs+1),train_acc_t5_values, label=\"Train\")\n",
        "plt.plot(range(1,num_epochs+1),val_acc_t5_values, label=\"Val\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.savefig('AccT5_p4.png')\n",
        "files.download('AccT5_p4.png')\n",
        "plt.clf()\n",
        "plt.close()\n",
        "plt.figure()\n",
        "plt.title(\"Loss vs. Number of Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(range(1,num_epochs+1),train_loss_values, label=\"Train\")\n",
        "plt.plot(range(1,num_epochs+1),val_loss_values, label=\"Val\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.savefig('Loss_p4.png')\n",
        "files.download('Loss_p4.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCvZsbnRT3Yn"
      },
      "source": [
        " پارامترها و کد اصلی و رسم نمودار مربوط به بخش 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRrLWzg3U7jE"
      },
      "source": [
        "# define parameters\n",
        "num_epochs = 30\n",
        "num_classes = 15\n",
        "feature_extract = False\n",
        "use_pretrained = True\n",
        "input_size = 224\n",
        "base_lr = 0.001\n",
        "batch_size = 32\n",
        "# main code\n",
        "model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "if feature_extract:\n",
        "  for param in model_ft.parameters():\n",
        "    param.requires_grad = False\n",
        "num_ftrs = model_ft.classifier[6].in_features\n",
        "model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if torch.cuda.is_available():\n",
        "  model_ft = model_ft.to('cuda')\n",
        "  criterion = criterion.to('cuda')\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer_ft, gamma=0.9)\n",
        "\n",
        "model_ft, train_loss_values, val_loss_values, train_acc_values, val_acc_values, train_acc_t5_values, val_acc_t5_values, best_acc = train_and_val_network(model_ft, criterion, optimizer_ft, scheduler, num_epochs)\n",
        "torch.save(model_ft, 'best_model_p5.pth')\n",
        "print(best_acc)\n",
        "# draw charts\n",
        "from google.colab import files\n",
        "plt.title(\"Accuracy vs. Number of Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.plot(range(1,num_epochs+1),train_acc_values, label=\"Train\")\n",
        "plt.plot(range(1,num_epochs+1),val_acc_values, label=\"Val\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.savefig('Acc_p5.png')\n",
        "files.download('Acc_p5.png')\n",
        "plt.clf()\n",
        "plt.close()\n",
        "plt.figure\n",
        "plt.title(\"Accuracy(top 5) vs. Number of Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.plot(range(1,num_epochs+1),train_acc_t5_values, label=\"Train\")\n",
        "plt.plot(range(1,num_epochs+1),val_acc_t5_values, label=\"Val\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.savefig('AccT5_p5.png')\n",
        "files.download('AccT5_p5.png')\n",
        "plt.clf()\n",
        "plt.close()\n",
        "plt.title(\"Loss vs. Number of Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(range(1,num_epochs+1),train_loss_values, label=\"Train\")\n",
        "plt.plot(range(1,num_epochs+1),val_loss_values, label=\"Val\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.savefig('Loss_p5.png')\n",
        "files.download('Loss_p5.png')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}